{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from CNN_Train.ipynb\n",
      "importing Jupyter notebook from CNN_Data.ipynb\n",
      "importing Jupyter notebook from CN_Network.ipynb\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../modules'))\n",
    "import notebook_loading\n",
    "\n",
    "from CNN_Train import CNN_Train\n",
    "from CNN_Data import *\n",
    "from CN_Network import CN_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extract the redundant baselines and their gains and data from miriad and calfits files\n",
    "red_bls, gains, uvd = load_relevant_data('../zen_data/zen.2458098.58037.xx.HH.uv','../zen_data/zen.2458098.58037.xx.HH.uv.abs.calfits')\n",
    "\n",
    "# seperate trining and testing redundant baselines \n",
    "# if we have not already done this, load them from disk\n",
    "training_redundant_baselines_dict, testing_redundant_baselines_dict = get_or_gen_test_train_red_bls_dicts(red_bls, gains.keys())\n",
    "\n",
    "# seperate the visiblites\n",
    "training_baselines_data = get_seps_data(training_redundant_baselines_dict, uvd)\n",
    "testing_baselines_data = get_seps_data(testing_redundant_baselines_dict, uvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cost_name': 'MSE',\n",
       " 'dtype': tf.float32,\n",
       " 'g_shift': 0.01,\n",
       " 'learning_rate': 5e-05,\n",
       " 'name': 'example_network-A',\n",
       " 'num_freq_channels': 1024,\n",
       " 'threshold': 0.00625,\n",
       " 'wide_filter_widths': [64, 32, 8],\n",
       " 'width_reduction_factors': [2, 3, 4]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_filter_widths = [64,32,8]\n",
    "width_reduction_factors = [2,3,4]\n",
    "learning_rate = 0.00005\n",
    "example_network = CN_Network(name = 'example_network-A',\n",
    "                             wide_filter_widths = wide_filter_widths,\n",
    "                             width_reduction_factors = width_reduction_factors,\n",
    "                             learning_rate = learning_rate)\n",
    "example_network.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Ready\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "example_network.train((training_baselines_data, training_redundant_baselines_dict),\n",
    "           (testing_baselines_data, testing_redundant_baselines_dict),\n",
    "           gains,\n",
    "           num_flatnesses = 5,\n",
    "           num_epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
