{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fully_CN_Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bn_fully_CN_Network(object):\n",
    "    \"\"\"A neural network of multi-path layers.\n",
    "       Filters for each path have shape_height = 1.\n",
    "       Parameters cannot be changed after initialzation. Create new network instead.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 name,\n",
    "                 wide_filter_widths,\n",
    "                 width_reduction_factors,\n",
    "                 dtype = tf.float32,\n",
    "                 num_freq_channels = 1024,\n",
    "                 learning_rate = 0.0001,\n",
    "                 cost_name = 'MSE',\n",
    "                 threshold = 0.00625,\n",
    "                 g_shift = 0.01,\n",
    "                 log_dir = 'logs/',\n",
    "                 num_1x1_conv_filters = 4):\n",
    "        \n",
    "        self.log_dir = log_dir#\n",
    "        \n",
    "        self.name = name\n",
    "        self.wide_filter_widths = wide_filter_widths\n",
    "        self.width_reduction_factors = width_reduction_factors\n",
    "        self.dtype = dtype\n",
    "        self.num_freq_channels = num_freq_channels\n",
    "        self.learning_rate = learning_rate\n",
    "        self.cost_name = cost_name\n",
    "        self.threshold = threshold\n",
    "        self.g_shift = g_shift\n",
    "        self.num_1x1_conv_filters = num_1x1_conv_filters\n",
    "                \n",
    "\n",
    "    def print_params(self):\n",
    "        \"\"\"Prints netwwork parameters\"\"\"\n",
    "        pprint(self._gen_params_dict())\n",
    "        \n",
    "    def load_params(self, path):\n",
    "        \"\"\"Load in the parameters of an old network, but keep the current network name.\"\"\"\n",
    "    \n",
    "        sys.stdout.write('\\rLoading Netowrk Parameters')\n",
    "        a = load(path + '.npz')\n",
    "        d = dict(zip((\"data1{}\".format(k) for k in a), (a[k] for k in a)))\n",
    "        \n",
    "        name = self.name\n",
    "        params = d['data1arr_0'][()]\n",
    "        for key in params:\n",
    "            setattr(self, key, params[key])\n",
    "        self.name = name\n",
    "\n",
    "    def _gen_params_dict(self):\n",
    "        d = self.__dict__\n",
    "        return {key : d[key] for key in d.keys() if key[0] != '_' if 'tensorflow' not in str(type(d[key]))}\n",
    "        \n",
    "    def _save_params(self):\n",
    "        direc = self.log_dir + self.name + '/params/'\n",
    "        \"\"\"Not safe - will overwrite existing file.\"\"\"\n",
    "        if not os.path.exists(direc):\n",
    "            os.makedirs(direc)\n",
    "            \n",
    "        np.savez(direc + self.__class__.__name__, self._gen_params_dict())   \n",
    "                \n",
    "    def create_graph(self):\n",
    "        self._save_params()\n",
    "        sys.stdout.write('\\rCreating Network Graph')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        def quad_path_layer(input, wide_conv_width, strides, layer_name, num_1x1_conv_filters = 4):\n",
    "\n",
    "            # convolution filters\n",
    "            conv_filters = lambda shape : tf.get_variable(name = 'filters',\n",
    "                                                          dtype = self.dtype,\n",
    "                                                          shape = shape,\n",
    "                                                          initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "\n",
    "            def _bias_add_scope(input, shape):\n",
    "                \"\"\"Creates a scope around a trainable bias and its addition to input\"\"\"\n",
    "                with tf.variable_scope('add_bias'):\n",
    "\n",
    "                    bias = tf.get_variable(name = 'biases', dtype = self.dtype, shape = shape, initializer = tf.contrib.layers.xavier_initializer())\n",
    "                    bias_add = tf.nn.bias_add(input, bias)\n",
    "\n",
    "                return bias_add\n",
    "\n",
    "\n",
    "            def _conv_scope(input, filter_shape, strides, scope_name = 'convolution'):\n",
    "                \"\"\"Creates a scope around a convolution.\"\"\"\n",
    "                with tf.variable_scope(scope_name):\n",
    "\n",
    "                    conv = tf.nn.conv2d(input = input, filter = conv_filters(filter_shape), strides = strides, padding = 'SAME') \n",
    "                    conv = _bias_add_scope(conv, [filter_shape[-1]])\n",
    "                    conv = tf.contrib.layers.batch_norm(conv, is_training = self.is_training)\n",
    "                    conv = tf.nn.relu(conv)\n",
    "                    conv = tf.nn.dropout(conv, self.conv_keep_prob)\n",
    "\n",
    "                return conv\n",
    "\n",
    "            def _avg_scope(input, strides, num_conv_filters):\n",
    "                \"\"\"Creates a scope around the average-pool path.\"\"\"\n",
    "                with tf.variable_scope('average'):\n",
    "                    avg_pool = tf.nn.avg_pool(value = input, ksize = strides, strides = strides, padding = \"SAME\")\n",
    "\n",
    "                    convolution_filter_shape = [1,1,avg_pool.get_shape().as_list()[3], num_conv_filters]\n",
    "                    avg = _conv_scope(avg_pool, convolution_filter_shape, [1,1,1,1], scope_name = \"1x1_conv\")\n",
    "\n",
    "                return avg\n",
    "\n",
    "            def _max_scope(input, strides,  num_conv_filters):\n",
    "                \"\"\"Creates a scope around the max-pool path\"\"\"\n",
    "                with tf.variable_scope('max'):\n",
    "                    max_pool = tf.nn.max_pool(value = input, ksize = strides, strides = strides, padding = \"SAME\")\n",
    "\n",
    "                    convolution_filter_shape = [1,1,max_pool.get_shape().as_list()[3],num_conv_filters]\n",
    "                    max_ = _conv_scope(max_pool, convolution_filter_shape, [1,1,1,1], scope_name = \"1x1_conv\")\n",
    "\n",
    "                return max_\n",
    "\n",
    "            def _filter_cat_scope(filters):\n",
    "                \"\"\"Creates a scope around filter concatation (layer output)\"\"\"\n",
    "                with tf.variable_scope('filter_cat'):\n",
    "                    filter_cat = tf.concat(filters, 3)\n",
    "                return filter_cat\n",
    "\n",
    "            ######\n",
    "\n",
    "            with tf.variable_scope(layer_name):\n",
    "\n",
    "                narrow_conv_width = wide_conv_width / 2\n",
    "\n",
    "                num_narrow_conv_filters = np.max([num_1x1_conv_filters / 2, 2])\n",
    "                num_wide_conv_filters = np.max([num_narrow_conv_filters / 2, 1])\n",
    "\n",
    "                _1x1_strides = [1,1,1,1]\n",
    "\n",
    "                avg_output = _avg_scope(input, strides, num_1x1_conv_filters)\n",
    "                max_output = _max_scope(input, strides, num_1x1_conv_filters)\n",
    "\n",
    "                inital_conv = _conv_scope(input, [1,1,input.get_shape().as_list()[3],num_1x1_conv_filters], [1,1,1,1], '1x1_conv')\n",
    "\n",
    "                narrow_convolution = _conv_scope(inital_conv, [1,narrow_conv_width,inital_conv.get_shape().as_list()[3],num_narrow_conv_filters], strides, scope_name = 'narrow')\n",
    "                wide_convolution = _conv_scope(inital_conv, [1,wide_conv_width,inital_conv.get_shape().as_list()[3],num_wide_conv_filters], strides, scope_name = 'wide')\n",
    "\n",
    "                catted_filters = _filter_cat_scope([avg_output, narrow_convolution, wide_convolution, max_output])\n",
    "\n",
    "            return catted_filters\n",
    "\n",
    "        # creates the network graph\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.is_training = tf.placeholder(dtype = tf.bool, name = 'is_training', shape = [])\n",
    "\n",
    "        with tf.variable_scope('keep_probs'):\n",
    "            \n",
    "            self.sample_keep_prob = tf.placeholder(self.dtype, name = 'sample_keep_prob')\n",
    "            self.conv_keep_prob = tf.placeholder(self.dtype, name = 'conv_keep_prob') \n",
    "            \n",
    "            # keep prob for the layer going into prediction\n",
    "            self.pred_keep_prob = tf.placeholder(self.dtype, name = 'pred_keep_prob')    \n",
    "\n",
    "\n",
    "\n",
    "        with tf.variable_scope('sample'):\n",
    "            # holds the 1 x num_channels samples that are fed into the network\n",
    "            self.X = tf.placeholder(self.dtype, shape = [None, 1, self.num_freq_channels, 1], name = 'X')\n",
    "            self.X_dropout = tf.nn.dropout(self.X, self.sample_keep_prob)\n",
    "\n",
    "        self._layers = []\n",
    "        num_layers = len(self.wide_filter_widths)\n",
    "        layer_names = ['layer_{}'.format(i) for i in range(num_layers)]\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            # previous layer is input for current layer\n",
    "            input = self.X_dropout if i == 0 else self._layers[i - 1]\n",
    "            strides = [1, 1, self.width_reduction_factors[i], 1]\n",
    "            q_layer = quad_path_layer(input, self.wide_filter_widths[i], strides, layer_names[i], num_1x1_conv_filters = self.num_1x1_conv_filters)\n",
    "            self._layers.append(q_layer)\n",
    "            \n",
    "        with tf.variable_scope('prediction'):\n",
    "            reshaped_final_layer = tf.contrib.layers.flatten(self._layers[-1])\n",
    "            reshaped_final_layer = tf.nn.dropout(reshaped_final_layer, self.pred_keep_prob)\n",
    "            prediction_weight = tf.get_variable(name = 'weight', shape = [reshaped_final_layer.get_shape()[-1], 1], dtype = self.dtype, initializer = tf.contrib.layers.xavier_initializer())\n",
    "            self.predictions = tf.matmul(reshaped_final_layer, prediction_weight)\n",
    "\n",
    "        with tf.variable_scope('targets'):\n",
    "            self.targets = tf.placeholder(dtype = self.dtype, shape = [None, 1], name = 'targets')\n",
    "\n",
    "        with tf.variable_scope('costs'):\n",
    "\n",
    "            error = tf.subtract(self.targets, self.predictions, name = 'error')\n",
    "            squared_error = tf.square(error, name = 'squared_difference')\n",
    "\n",
    "            with tf.variable_scope('mean_inverse_shifted_gaussian'):\n",
    "                with tf.variable_scope('normal_distribution'):\n",
    "                    \n",
    "                    sigma = tf.constant(self.threshold, name = 'sigma')\n",
    "                    normal_dist = tf.contrib.distributions.Normal(0.0, sigma, name = 'normal_dist')\n",
    "                    gaussian_prob = normal_dist.prob(error, name = 'gaussian_prob')\n",
    "                    shift = tf.constant(self.g_shift, name = 'gaussian_shift_value')\n",
    "                    shifted_gaussian = tf.add(gaussian_prob, shift, name = 'shifted_gaussian')   \n",
    "                    \n",
    "                self.MISG = tf.reduce_mean(tf.divide(1.0, shifted_gaussian), name = 'mean_inverse_shifted_gaussian')\n",
    "                \n",
    "            with tf.variable_scope('mean_squared_error'):\n",
    "                self.MSE = tf.reduce_mean(squared_error)\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            with tf.variable_scope('train'):\n",
    "            \n",
    "                cost = self.MSE if self.cost_name == 'MSE' else self.MISG\n",
    "                LR = tf.constant(self.learning_rate, name = 'learning_rate')\n",
    "\n",
    "                self.optimizer = tf.train.AdamOptimizer(LR, epsilon=1e-08).minimize(cost)\n",
    "\n",
    "        with tf.variable_scope('logging'):  \n",
    "\n",
    "            with tf.variable_scope('image'):\n",
    "                self.image_buf = tf.placeholder(tf.string, shape=[])\n",
    "                epoch_image = tf.expand_dims(tf.image.decode_png(self.image_buf, channels=4), 0)\n",
    "\n",
    "            with tf.variable_scope('percent_within_threshold'):\n",
    "                self.PWT = 100.*tf.reduce_mean(tf.cast(tf.less_equal(tf.abs(self.targets - self.predictions), sigma), self.dtype) )\n",
    "\n",
    "\n",
    "            tf.summary.histogram(name = 'targets', values = self.targets)\n",
    "            tf.summary.histogram(name = 'predictions',values =  self.predictions)\n",
    "            tf.summary.scalar(name = 'MSE', tensor = self.MSE)\n",
    "            tf.summary.scalar(name = 'MISG', tensor = self.MISG)\n",
    "            tf.summary.scalar(name = 'PWT', tensor = self.PWT)\n",
    "            tf.summary.image('prediction_vs_actual', epoch_image)\n",
    "            self.summary = tf.summary.merge_all()\n",
    "            \n",
    "        sys.stdout.write('\\rNetwork Ready')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
