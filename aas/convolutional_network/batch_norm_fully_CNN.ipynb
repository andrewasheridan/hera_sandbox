{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../modules'))\n",
    "\n",
    "from Restoreable_Component import Restoreable_Component\n",
    "from Quad_Path_Layer import Quad_Path_Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class CNN_QP_BN_R(Restoreable_Component):\n",
    "    \"\"\"CNN: Convolutional neural network.\n",
    "       QP: Each computational layer is a quad-path layer.\n",
    "       BN: All non-linearalities have batch-normalization applied.\n",
    "       R: Regression, this network predicts a single value for each input.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 name,\n",
    "                 wide_convolution_filter_widths,\n",
    "                 layer_downsampling_factors, \n",
    "                 num_1x1_conv_filters_per_layer,\n",
    "                 log_dir = 'logs/',\n",
    "                 dtype = tf.float32,\n",
    "                 adam_initial_learning_rate = 0.0001,\n",
    "                 cost = 'MSE',\n",
    "                 accuracy_threshold = 0.00625,\n",
    "                 gaussian_shift_scalar = 1e-5):\n",
    "    \n",
    "        Restoreable_Component.__init__(self, name=name, log_dir=log_dir)\n",
    "                \n",
    "        self.wide_convolution_filter_widths = wide_convolution_filter_widths\n",
    "        self.layer_downsampling_factors = layer_downsampling_factors\n",
    "        \n",
    "        self.dtype = dtype\n",
    "        self.adam_initial_learning_rate = adam_initial_learning_rate\n",
    "        self.cost = cost\n",
    "        self.accuracy_threshold = accuracy_threshold\n",
    "        self.gaussian_shift_scalar = gaussian_shift_scalar\n",
    "        self.num_1x1_conv_filters_per_layer = num_1x1_conv_filters_per_layer \n",
    "        \n",
    "        self.num_freq_channels = 1024\n",
    "        \n",
    "    def create_graph(self):\n",
    "        \n",
    "        self.save_params()\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.is_training = tf.placeholder(dtype = tf.bool, name = 'is_training', shape = [])\n",
    "        \n",
    "        with tf.variable_scope('keep_probs'):\n",
    "            \n",
    "            self.sample_keep_prob = tf.placeholder(self.dtype, name = 'sample_keep_prob')\n",
    "            self.conv_keep_prob = tf.placeholder(self.dtype, name = 'conv_keep_prob') \n",
    "            self.pred_keep_prob = tf.placeholder(self.dtype, name = 'pred_keep_prob')    \n",
    "\n",
    "        with tf.variable_scope('samples'):\n",
    "            \n",
    "            self.samples = tf.placeholder(self.dtype, shape = [None, 1, self.num_freq_channels, 1], name = 'samples')\n",
    "            self.samples = tf.nn.dropout(self.samples, self.sample_keep_prob)\n",
    "\n",
    "        self._layers = []\n",
    "        num_layers = len(self.wide_convolution_filter_widths)\n",
    "        layer_names = ['layer_{}'.format(i) for i in range(num_layers)]\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            # previous layer is input for current layer\n",
    "            layer = self.samples if i == 0 else self._layers[i - 1]\n",
    "            layer = Quad_Path_Layer(layer,\n",
    "                                    layer_names[i],\n",
    "                                    self.wide_convolution_filter_widths[i],\n",
    "                                    self.layer_downsampling_factors[i],\n",
    "                                    self.num_1x1_conv_filters_per_layer[i],\n",
    "                                    self.conv_keep_prob,\n",
    "                                    self.is_training,\n",
    "                                    self.dtype)\n",
    "            layer = layer.process()\n",
    "            \n",
    "            self._layers.append(layer)\n",
    "            \n",
    "        with tf.variable_scope('prediction'):\n",
    "            reshaped_final_layer = tf.contrib.layers.flatten(self._layers[-1])\n",
    "            reshaped_final_layer = tf.nn.dropout(reshaped_final_layer, self.pred_keep_prob)\n",
    "            prediction_weight = tf.get_variable(name = 'weight', shape = [reshaped_final_layer.get_shape()[-1], 1], dtype = self.dtype, initializer = tf.contrib.layers.xavier_initializer())\n",
    "            self.predictions = tf.matmul(reshaped_final_layer, prediction_weight)\n",
    "\n",
    "        with tf.variable_scope('targets'):\n",
    "            self.targets = tf.placeholder(dtype = self.dtype, shape = [None, 1], name = 'targets')\n",
    "\n",
    "        with tf.variable_scope('costs'):\n",
    "\n",
    "            error = tf.subtract(self.targets, self.predictions, name = 'error')\n",
    "            squared_error = tf.square(error, name = 'squared_difference')\n",
    "\n",
    "            with tf.variable_scope('mean_inverse_shifted_gaussian'):\n",
    "\n",
    "                normal_dist = tf.contrib.distributions.Normal(0.0, self.accuracy_threshold, name = 'normal_dist')\n",
    "                gaussian_prob = normal_dist.prob(error, name = 'gaussian_prob')\n",
    "                shifted_gaussian = tf.add(gaussian_prob, self.gaussian_shift_scalar, name = 'shifted_gaussian')   \n",
    "\n",
    "                self.MISG = tf.reduce_mean(tf.divide(1.0, shifted_gaussian), name = 'mean_inverse_shifted_gaussian')\n",
    "                \n",
    "            with tf.variable_scope('mean_squared_error'):\n",
    "                self.MSE = tf.reduce_mean(squared_error)\n",
    "\n",
    "\n",
    "        with tf.variable_scope('logging'):  \n",
    "\n",
    "            with tf.variable_scope('image'):\n",
    "                \n",
    "                self.image_buf = tf.placeholder(tf.string, shape=[])\n",
    "                epoch_image = tf.expand_dims(tf.image.decode_png(self.image_buf, channels=4), 0)\n",
    "\n",
    "            with tf.variable_scope('percent_within_threshold'):\n",
    "                self.PWT = 100.*tf.reduce_mean(tf.cast(tf.less_equal(tf.abs(self.targets - self.predictions), self.accuracy_threshold), self.dtype) )\n",
    "\n",
    "\n",
    "            tf.summary.histogram(name = 'targets', values = self.targets)\n",
    "            tf.summary.histogram(name = 'predictions',values =  self.predictions)\n",
    "            tf.summary.scalar(name = 'MSE', tensor = self.MSE)\n",
    "            tf.summary.scalar(name = 'MISG', tensor = self.MISG)\n",
    "            tf.summary.scalar(name = 'PWT', tensor = self.PWT)\n",
    "            tf.summary.image('prediction_vs_actual', epoch_image)\n",
    "            self.summary = tf.summary.merge_all()\n",
    "            \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            with tf.variable_scope('train'):\n",
    "            \n",
    "                if self.cost == 'MSE':\n",
    "                    cost = self.MSE\n",
    "                if self.cost == 'MISG':\n",
    "                    cost = self.MISG\n",
    "                if self.cost == 'PWT_weighted_MSE':\n",
    "                    cost = self.MSE * (100. - self.PWT)\n",
    "                if self.cost == 'PWT_weighted_MISG':\n",
    "                    cost = self.MISG * (100. - self.PWT)\n",
    "\n",
    "\n",
    "                self.optimizer = tf.train.AdamOptimizer(self.adam_initial_learning_rate, epsilon=1e-08).minimize(cost)\n",
    "            \n",
    "        sys.stdout.write('\\rNetwork Ready ...')\n",
    "        num_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "        sys.stdout.write('\\rNetwork Ready - {} trainable parameters'.format(num_trainable_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
