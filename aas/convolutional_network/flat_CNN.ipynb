{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flat_CNN.ipynb`\n",
    "\n",
    "Create a convolutional neural network that uses filters of height = 1 to determine the slope angle of phase data. Each sample input will be an array of angle data, shape = (1x1024) (One time x 1024 frequency channels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flat CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_plot(self,predicted_values, actual_values):\n",
    "    \"\"\"Create a prediction plot and save to byte string.\"\"\"\n",
    "\n",
    "    prediction_unscaled = delay_itx(predicted_values)\n",
    "    actual_unscaled = delay_itx(actual_values)\n",
    "\n",
    "    sorting_idx = np.argsort(actual_unscaled.T[0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (5, 3), dpi = 144)\n",
    "\n",
    "    ax.plot(prediction_unscaled.T[0][sorting_idx],\n",
    "            linestyle = 'none', marker = '.', markersize = 1,\n",
    "            color = 'darkblue')\n",
    "\n",
    "    ax.plot(actual_unscaled.T[0][sorting_idx],\n",
    "            linestyle = 'none', marker = '.', markersize = 1, alpha = 0.50,\n",
    "            color = '#E50000')       \n",
    "\n",
    "    ax.set_title('std: %.9f' %np.std(prediction_unscaled.T[0][sorting_idx] - actual_unscaled.T[0][sorting_idx]))\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', dpi = 144)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "\n",
    "    return buf.getvalue()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flat_CNN(object):\n",
    "    \"\"\"A neural network of multi-path layers. Filters for each path have shape_height = 1\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 wide_filter_widths = [],\n",
    "                 width_reduction_factors = [],\n",
    "                 dtype = tf.float32,\n",
    "                 num_freq_channels = 1024,\n",
    "                 learning_rate = 0.0001):\n",
    "\n",
    "        self.wide_filter_widths = wide_filter_widths\n",
    "        self.width_reduction_factors = width_reduction_factors\n",
    "        self.dtype = dtype\n",
    "        self.num_freq_channels = num_freq_channels\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.num_layers = len(self.wide_filter_widths)\n",
    "        \n",
    "        \n",
    "    def _quad_path_layer(self, input, wide_conv_width, strides, layer_name, num_1x1_conv_filters = 16):\n",
    "\n",
    "        # convolution filters\n",
    "        conv_filters = lambda shape : tf.get_variable(name = 'filters',\n",
    "                                                      dtype = self.dtype,\n",
    "                                                      shape = shape,\n",
    "                                                      initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "\n",
    "        def _bias_add_scope(input, shape):\n",
    "            \"\"\"Creates a scope around a trainable bias and its addition to input\"\"\"\n",
    "            with tf.variable_scope('add_bias'):\n",
    "\n",
    "                bias = tf.get_variable(name = 'bias', dtype = self.dtype, shape = shape, initializer = tf.contrib.layers.xavier_initializer())\n",
    "                bias_add = tf.nn.bias_add(input, bias)\n",
    "\n",
    "            return bias_add\n",
    "\n",
    "\n",
    "        def _conv_scope(input, filter_shape, strides, scope_name = 'convolution'):\n",
    "            \"\"\"Creates a scope around a convolution.\"\"\"\n",
    "            with tf.variable_scope(scope_name):\n",
    "\n",
    "                conv = tf.nn.conv2d(input = input, filter = conv_filters(filter_shape), strides = strides, padding = 'SAME') \n",
    "                conv = _bias_add_scope(conv, [filter_shape[-1]])\n",
    "                conv = tf.nn.relu(conv)\n",
    "                conv = tf.nn.dropout(conv, self.conv_keep_prob)\n",
    "\n",
    "            return conv\n",
    "\n",
    "        def _avg_scope(input, strides, num_conv_filters):\n",
    "            \"\"\"Creates a scope around the average-pool path.\"\"\"\n",
    "            with tf.variable_scope('average'):\n",
    "                avg_pool = tf.nn.avg_pool(value = input, ksize = strides, strides = strides, padding = \"SAME\")\n",
    "\n",
    "                convolution_filter_shape = [1,1,avg_pool.get_shape().as_list()[3], num_conv_filters]\n",
    "                avg = _conv_scope(avg_pool, convolution_filter_shape, [1,1,1,1], scope_name = \"1x1_conv\")\n",
    "\n",
    "            return avg\n",
    "\n",
    "        def _max_scope(input, strides,  num_conv_filters):\n",
    "            \"\"\"Creates a scope around the max-pool path\"\"\"\n",
    "            with tf.variable_scope('max'):\n",
    "                max_pool = tf.nn.max_pool(value = input, ksize = strides, strides = strides, padding = \"SAME\")\n",
    "\n",
    "                convolution_filter_shape = [1,1,max_pool.get_shape().as_list()[3],num_conv_filters]\n",
    "                max_ = _conv_scope(max_pool, convolution_filter_shape, [1,1,1,1], scope_name = \"1x1_conv\")\n",
    "\n",
    "            return max_\n",
    "\n",
    "        def _filter_cat_scope(filters):\n",
    "            \"\"\"Creates a scope around filter concatation (layer output)\"\"\"\n",
    "            with tf.variable_scope('filter_cat'):\n",
    "                filter_cat = tf.concat(filters, 3)\n",
    "            return filter_cat\n",
    "\n",
    "        ######\n",
    "\n",
    "        with tf.variable_scope(layer_name):\n",
    "\n",
    "            narrow_conv_width = wide_conv_width / 2\n",
    "\n",
    "            num_narrow_conv_filters = num_1x1_conv_filters / 2\n",
    "            num_wide_conv_filters = num_narrow_conv_filters / 2\n",
    "\n",
    "            _1x1_strides = [1,1,1,1]\n",
    "\n",
    "            avg_output = _avg_scope(input, strides, num_1x1_conv_filters)\n",
    "            max_output = _max_scope(input, strides, num_1x1_conv_filters)\n",
    "\n",
    "            inital_conv = _conv_scope(input, [1,1,input.get_shape().as_list()[3],num_1x1_conv_filters], [1,1,1,1], '1x1_conv')\n",
    "\n",
    "            narrow_convolution = _conv_scope(inital_conv, [1,narrow_conv_width,inital_conv.get_shape().as_list()[3],num_narrow_conv_filters], strides, scope_name = 'narrow')\n",
    "            wide_convolution = _conv_scope(inital_conv, [1,wide_conv_width,inital_conv.get_shape().as_list()[3],num_wide_conv_filters], strides, scope_name = 'wide')\n",
    "\n",
    "            catted_filters = _filter_cat_scope([avg_output, narrow_convolution, wide_convolution, max_output])\n",
    "\n",
    "        return catted_filters\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def create_graph(self):\n",
    "        # creates the network graph\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        # Note, tf.placeholder() are assigned by tf.Session()\n",
    "\n",
    "        with tf.variable_scope('keep_probs'):\n",
    "            # Dropout rate = 1 - keep_prob\n",
    "\n",
    "            # probability of keeping sample_keep_prob\n",
    "            # suggest 0.8\n",
    "            self.sample_keep_prob = tf.placeholder(self.dtype, name = 'sample_keep_prob')\n",
    "\n",
    "            # probability of keeping convolution output\n",
    "            # suggest 0.9\n",
    "            self.conv_keep_prob = tf.placeholder(self.dtype, name = 'conv_keep_prob')\n",
    "\n",
    "            # probability of keeping fully connected layer output\n",
    "            # suggest 0.95\n",
    "            self.fcl_keep_prob = tf.placeholder(self.dtype, name = 'fcl_keep_prob')        \n",
    "\n",
    "        with tf.variable_scope('sample'):\n",
    "            # holds the 1 x num_channels samples that are fed into the network\n",
    "            self.X = tf.placeholder(self.dtype, shape = [None, 1, self.num_freq_channels, 1], name = 'X')\n",
    "            self.X_dropout = tf.nn.dropout(self.X, self.sample_keep_prob)\n",
    "\n",
    "        self.layers = []\n",
    "        layer_names = ['layer_{}'.format(i) for i in range(self.num_layers)]\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            # previous layer is input for current layer\n",
    "            input = self.X_dropout if i == 0 else self.layers[i - 1]\n",
    "            strides = [1, 1, self.width_reduction_factors[i], 1]\n",
    "            q_layer = self._quad_path_layer(input, self.wide_filter_widths[i], strides, layer_names[i])\n",
    "            self.layers.append(q_layer)\n",
    "                \n",
    "        with tf.variable_scope('fcl_1'):\n",
    "            \n",
    "            bias = tf.get_variable(name = 'bias',\n",
    "                                   shape = self.layers[-1].get_shape().as_list()[3],\n",
    "                                   initializer = tf.contrib.layers.xavier_initializer())\n",
    "            weights = tf.get_variable(name = 'weights',\n",
    "                                      shape = [self.layers[-1].get_shape().as_list()[2]*self.layers[-1].get_shape().as_list()[3], self.layers[-1].get_shape().as_list()[3]])\n",
    "            \n",
    "            fcl_1 = tf.reshape(self.layers[-1], [self.layers[-1].get_shape().as_list()[2], tf.reduce_prod(self.layers[-1].get_shape()[1:])])\n",
    "            fcl_1 = tf.matmul(fcl_1, weights)\n",
    "            fcl_1 = tf.nn.relu6(tf.nn.bias_add(fcl_1, bias))\n",
    "            fcl_1 = tf.nn.dropout(fcl_1, self.fcl_keep_prob)\n",
    "                \n",
    "            self.layers.append(fcl_1)\n",
    "            \n",
    "        with tf.variable_scope('fcl_2'):\n",
    "            \n",
    "            bias = tf.get_variable(name = 'bias',\n",
    "                                   shape = 4,\n",
    "                                   initializer = tf.contrib.layers.xavier_initializer())\n",
    "            weights = tf.get_variable(name = 'weights',\n",
    "                                      shape = [self.layers[-1].get_shape().as_list()[1], 4])\n",
    "            \n",
    "            fcl_2 = tf.matmul(self.layers[-1], weights)\n",
    "            fcl_2 = tf.nn.relu6(tf.nn.bias_add(fcl_2, bias))\n",
    "            fcl_2 = tf.nn.dropout(fcl_2, self.fcl_keep_prob)\n",
    "                \n",
    "            self.layers.append(fcl_2)\n",
    "            \n",
    "        with tf.variable_scope('prediction'):\n",
    "            reshape_final_layer = tf.reshape(self.layers[-1], [-1, np.prod(self.layers[-1].get_shape())])\n",
    "            prediction_weight = tf.get_variable(name = 'weight', shape = [np.prod(self.layers[-1].get_shape()), 1.], dtype = self.dtype, initializer = tf.contrib.layers.xavier_initializer())\n",
    "            pred_times_weight = tf.matmul(reshape_final_layer, prediction_weight)\n",
    "            self.predictions = tf.nn.bias_add(pred_times_weight, [1])\n",
    "\n",
    "        with tf.variable_scope('targets'):\n",
    "            self.targets = tf.placeholder(dtype = self.dtype, shape = [None, 1], name = 'targets')\n",
    "\n",
    "        with tf.variable_scope('costs'):\n",
    "\n",
    "            self.error = tf.subtract(self.targets, self.predictions, name = 'error')\n",
    "            self.squared_error = tf.square(self.error, name = 'squared_difference')\n",
    "\n",
    "            with tf.variable_scope('mean_inverse_shifted_gaussian'):\n",
    "                with tf.variable_scope('normal_distribution'):\n",
    "                    self.threshold = 0.00625\n",
    "                    sigma = tf.constant(self.threshold, name = 'sigma')\n",
    "                    normal_dist = tf.contrib.distributions.Normal(0.0, sigma, name = 'normal_dist')\n",
    "                    gaussian_prob = normal_dist.prob(self.error, name = 'gaussian_prob')\n",
    "                    shifted_gaussian = tf.add(gaussian_prob, .01, name = 'shifted_gaussian')        \n",
    "\n",
    "                self.MISG = tf.reduce_mean(tf.divide(1.0, shifted_gaussian), name = 'mean_inverse_shifted_gaussian')\n",
    "\n",
    "            with tf.variable_scope('mean_squared_error'):\n",
    "                self.MSE = tf.reduce_mean(self.squared_error)\n",
    "\n",
    "        with tf.variable_scope('train'):\n",
    "\n",
    "            optimizer = tf.train.AdamOptimizer(self.learning_rate, epsilon=1e-08).minimize(self.MISG)\n",
    "\n",
    "        with tf.variable_scope('logging'):  \n",
    "\n",
    "            with tf.variable_scope('image'):\n",
    "                self.image_buf = tf.placeholder(tf.string, shape=[])\n",
    "                epoch_image = tf.expand_dims(tf.image.decode_png(self.image_buf, channels=4), 0)\n",
    "\n",
    "            with tf.variable_scope('percent_within_threshold'):\n",
    "                self.PWT = tf.reduce_mean(tf.cast(tf.less_equal(self.targets - self.predictions, self.threshold), self.dtype) )\n",
    "\n",
    "\n",
    "            tf.summary.histogram(name = 'targets', values = self.targets)\n",
    "            tf.summary.histogram(name = 'predictions',values =  self.predictions)\n",
    "            tf.summary.scalar(name = 'MSE', tensor = self.MSE)\n",
    "            tf.summary.scalar(name = 'MISG', tensor = self.MISG)\n",
    "            tf.summary.scalar(name = 'PWT', tensor = self.PWT)\n",
    "            tf.summary.image('prediction_vs_actual', epoch_image)\n",
    "            self.summary = tf.summary.merge_all()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Flat_CNN([64, 32, 16],[2,4,4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
