{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(object):\n",
    "    \"\"\"A neural network of fully connected layers.\n",
    "    \n",
    "    First layer has Leaky_ReLU activation with a trainable alpha. Other layers have ReLU activation.\n",
    "    Input sample has dropout at rate 1 - sample_keep_prob.\n",
    "    activations have dropout at rate 1 - fcl_keep_prob.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 layer_nodes,\n",
    "                 learning_rate = 0.0001,\n",
    "                 dtype = tf.float32):\n",
    "        \n",
    "        self.layer_nodes = layer_nodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.layers = []\n",
    "        self.layer_names = ['layer_{}'.format(i) for i in range(len(self.layer_nodes))]\n",
    "        \n",
    "    def create_graph(self):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        with tf.variable_scope('keep_probs'):\n",
    "\n",
    "            self.sample_keep_prob = tf.placeholder(self.dtype, name = 'sample_keep_prob')\n",
    "\n",
    "            self.fcl_keep_prob = tf.placeholder(self.dtype, name = 'fcl_keep_prob')  \n",
    "            \n",
    "        with tf.variable_scope('sample'):\n",
    "\n",
    "            self.X = tf.placeholder(self.dtype, shape = [None, 1024], name = 'X')\n",
    "            self.X = tf.nn.dropout(self.X, self.sample_keep_prob)\n",
    "            \n",
    "        with tf.variable_scope('input_layer'):\n",
    "            \n",
    "            b = tf.get_variable(name = 'bias', shape = [self.layer_nodes[0]],\n",
    "                                initializer = tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "            w = tf.get_variable(name = 'weights', shape  = [1024, self.layer_nodes[0]],\n",
    "                                initializer = tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "            self.leaky_relu_alpha = tf.get_variable(name = 'leaky_relu_alpha',\n",
    "                                                    shape = [1],\n",
    "                                                    dtype = self.dtype)\n",
    "            \n",
    "            layer = tf.nn.leaky_relu(tf.matmul(self.X, w) + b, alpha = self.leaky_relu_alpha)\n",
    "            layer = tf.nn.dropout(layer, self.fcl_keep_prob)\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        for i in range(len(self.layer_nodes)):\n",
    "            if i > 0:\n",
    "                with tf.variable_scope('layer_%d' %(i)):\n",
    "                    layer = tf.contrib.layers.fully_connected(self.layers[i-1], self.layer_nodes[i])\n",
    "                    layer = tf.nn.dropout(layer, self.fcl_keep_prob)\n",
    "                    self.layers.append(layer)\n",
    "\n",
    "                    \n",
    "        with tf.variable_scope('prediction'):\n",
    "            self.predictions = tf.contrib.layers.fully_connected(self.layers[-1], 1)\n",
    "\n",
    "\n",
    "        with tf.variable_scope('targets'):\n",
    "            self.targets  = tf.placeholder(self.dtype, shape = (None, 1), name = 'targets')\n",
    "\n",
    "            \n",
    "            \n",
    "        with tf.variable_scope('costs'):\n",
    "\n",
    "            error = tf.subtract(self.targets, self.predictions, name = 'error')\n",
    "            squared_error = tf.square(error, name = 'squared_difference')\n",
    "\n",
    "            with tf.variable_scope('mean_inverse_shifted_gaussian'):\n",
    "                with tf.variable_scope('normal_distribution'):\n",
    "                    sigma = tf.constant(0.00625, name = 'sigma')\n",
    "                    normal_dist = tf.contrib.distributions.Normal(0.0, sigma, name = 'normal_dist')\n",
    "                    gaussian_prob = normal_dist.prob(error, name = 'gaussian_prob')\n",
    "                    shift = tf.constant(0.01, name = 'shift')\n",
    "                    shifted_gaussian = tf.add(gaussian_prob, shift, name = 'shifted_gaussian')        \n",
    "\n",
    "                self.MISG = tf.reduce_mean(tf.divide(1.0, shifted_gaussian), name = 'mean_inverse_shifted_gaussian')\n",
    "\n",
    "            with tf.variable_scope('mean_squared_error'):\n",
    "                self.MSE = tf.reduce_mean(squared_error)\n",
    "        \n",
    "        with tf.variable_scope('train'):\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate, epsilon=1e-08).minimize(self.MISG + 100.*self.MSE)\n",
    "            \n",
    "        with tf.variable_scope('logging'):  \n",
    "\n",
    "            with tf.variable_scope('image'):\n",
    "                self.image_buf = tf.placeholder(tf.string, shape=[])\n",
    "                epoch_image = tf.expand_dims(tf.image.decode_png(self.image_buf, channels=4), 0)\n",
    "\n",
    "            with tf.variable_scope('percent_within_threshold'):\n",
    "                self.PWT = 100.*tf.reduce_mean(tf.cast(tf.less_equal(tf.abs(self.targets - self.predictions), sigma), self.dtype) )\n",
    "\n",
    "            tf.summary.histogram(name = 'targets', values = self.targets)\n",
    "            tf.summary.histogram(name = 'predictions',values =  self.predictions)\n",
    "            tf.summary.scalar(name = 'MSE', tensor = self.MSE)\n",
    "            tf.summary.scalar(name = 'MISG', tensor = self.MISG)\n",
    "            tf.summary.scalar(name = 'PWT', tensor = self.PWT)\n",
    "            tf.summary.image('prediction_vs_actual', epoch_image)\n",
    "            self.summary = tf.summary.merge_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
